{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Assignment 3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "736WfGSYASSI",
        "outputId": "52c6f9d5-ff32-4f87-8000-406022c36b41"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in d:\\nieuwe map\\lib\\site-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in d:\\nieuwe map\\lib\\site-packages (from pyspark) (0.10.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7re-oxBASSO"
      },
      "source": [
        "#pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
        "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
        "from pyspark.sql.types import StringType,IntegerType\n",
        "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaSt3r4kASSP",
        "outputId": "14ce80e3-3a12-4a10-fe80-89ad9d15aa4f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "train = spark.read.load(\"D:\\Master HIR\\Advanced analytics\\Assignment 3\\ Tweets Simen.csv\",\n",
        "                     format=\"csv\", sep=\";\", inferSchema=\"true\", header=\"true\")\n",
        "\n",
        "train.printSchema()\n",
        "train.head()\n",
        "train.describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Builder' object has no attribute 'read_options'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-16-30dcaf73f479>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\Master HIR\\Advanced analytics\\Assignment 3/ Tweets Simen.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Builder' object has no attribute 'read_options'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4QHxYA-ASSQ"
      },
      "source": [
        "feat_cols= ['_c0', '_c1']\n",
        "vec_assem= VectorAssembler(inputCols=feat_cols, outputCol='features')\n",
        "final_train= vec_assem.transform(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIN26NaPASSR",
        "outputId": "d244a93d-7aba-4634-e5fb-e76d9956a5ae"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train = spark.read.csv(f' Tweets Simen.csv', header = True, inferSchema = True)\n",
        "train.printSchema()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Builder' object has no attribute 'read_csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-93b8525f7065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf' Tweets Simen.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferSchema\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'Builder' object has no attribute 'read_csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJRtxbudASSS"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "\n",
        "regexp_replace(col(‘text’), ‘\\d+’, ‘’)\n",
        "pd.DataFrame(sdf_train.take(5), columns=sdf_train.columns)\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "for w in example_words:\n",
        "    print(ps.stem(w))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}